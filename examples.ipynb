{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCW-xvckaO8s"
      },
      "source": [
        "# Live Colab Example\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/microsoft/BiomedParse.git"
      ],
      "metadata": {
        "id": "vjYVDS3ywUTM",
        "outputId": "b9bc1444-0826-4a1f-8159-8dc1f41ae65b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'BiomedParse'...\n",
            "remote: Enumerating objects: 1777, done.\u001b[K\n",
            "remote: Counting objects: 100% (140/140), done.\u001b[K\n",
            "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
            "\n",
            "remote: Total 1777 (delta 105), reused 95 (delta 95), pack-reused 1637 (from 2)\u001b[K\n",
            "Receiving objects: 100% (1777/1777), 674.10 MiB | 36.70 MiB/s, done.\n",
            "Resolving deltas: 100% (556/556), done.\n",
            "Updating files: 100% (583/583), done.\n",
            "Filtering content: 100% (45/45), 69.68 MiB | 35.44 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r BiomedParse/assets/requirements/requirements.txt"
      ],
      "metadata": {
        "id": "ri-vLPBaxfNX",
        "outputId": "25f04c1a-f3ce-4f83-b36b-71db3ba887ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/MaureenZOU/detectron2-xyz.git (from -r BiomedParse/assets/requirements/requirements.txt (line 33))\n",
            "  Cloning https://github.com/MaureenZOU/detectron2-xyz.git to /tmp/pip-req-build-ss8ua_sh\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/MaureenZOU/detectron2-xyz.git /tmp/pip-req-build-ss8ua_sh\n",
            "  Resolved https://github.com/MaureenZOU/detectron2-xyz.git to commit 42121d75e10d9f858f3a91b6a39f5722c02868f0\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pillow==9.4.0 (from -r BiomedParse/assets/requirements/requirements.txt (line 1))\n",
            "  Downloading Pillow-9.4.0.tar.gz (50.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting opencv-python==4.8.1.78 (from -r BiomedParse/assets/requirements/requirements.txt (line 2))\n",
            "  Downloading opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Collecting pyyaml==6.0.1 (from -r BiomedParse/assets/requirements/requirements.txt (line 3))\n",
            "  Downloading PyYAML-6.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting json_tricks==3.17.3 (from -r BiomedParse/assets/requirements/requirements.txt (line 4))\n",
            "  Downloading json_tricks-3.17.3-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Collecting yacs==0.1.8 (from -r BiomedParse/assets/requirements/requirements.txt (line 5))\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Collecting scikit-learn==1.3.1 (from -r BiomedParse/assets/requirements/requirements.txt (line 6))\n",
            "  Downloading scikit_learn-1.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting pandas==2.0.3 (from -r BiomedParse/assets/requirements/requirements.txt (line 7))\n",
            "  Downloading pandas-2.0.3.tar.gz (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m135.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting timm==0.4.12 (from -r BiomedParse/assets/requirements/requirements.txt (line 8))\n",
            "  Downloading timm-0.4.12-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting numpy==1.26.4 (from -r BiomedParse/assets/requirements/requirements.txt (line 9))\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops==0.8.0 (from -r BiomedParse/assets/requirements/requirements.txt (line 10))\n",
            "  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting fvcore==0.1.5.post20221221 (from -r BiomedParse/assets/requirements/requirements.txt (line 11))\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers==4.34.0 (from -r BiomedParse/assets/requirements/requirements.txt (line 12))\n",
            "  Downloading transformers-4.34.0-py3-none-any.whl.metadata (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.5/121.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece==0.1.99 (from -r BiomedParse/assets/requirements/requirements.txt (line 13))\n",
            "  Downloading sentencepiece-0.1.99.tar.gz (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m112.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy==6.1.1 (from -r BiomedParse/assets/requirements/requirements.txt (line 14))\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting regex==2023.10.3 (from -r BiomedParse/assets/requirements/requirements.txt (line 15))\n",
            "  Downloading regex-2023.10.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nltk==3.8.1 (from -r BiomedParse/assets/requirements/requirements.txt (line 16))\n",
            "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting mpi4py==3.1.5 (from -r BiomedParse/assets/requirements/requirements.txt (line 17))\n",
            "  Downloading mpi4py-3.1.5.tar.gz (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting vision-datasets==0.2.2 (from -r BiomedParse/assets/requirements/requirements.txt (line 18))\n",
            "  Downloading vision_datasets-0.2.2-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting cython==3.0.2 (from -r BiomedParse/assets/requirements/requirements.txt (line 19))\n",
            "  Downloading Cython-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.1 kB)\n",
            "Collecting pycocotools==2.0.7 (from -r BiomedParse/assets/requirements/requirements.txt (line 20))\n",
            "  Downloading pycocotools-2.0.7.tar.gz (24 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting diffdist==0.1 (from -r BiomedParse/assets/requirements/requirements.txt (line 21))\n",
            "  Downloading diffdist-0.1.tar.gz (4.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scikit-image==0.21.0 (from -r BiomedParse/assets/requirements/requirements.txt (line 25))\n",
            "  Downloading scikit_image-0.21.0.tar.gz (22.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.7/22.7 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mup==1.0.0 (from -r BiomedParse/assets/requirements/requirements.txt (line 26))\n",
            "  Downloading mup-1.0.0.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting accelerate==0.23.0 (from -r BiomedParse/assets/requirements/requirements.txt (line 27))\n",
            "  Downloading accelerate-0.23.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting kornia==0.7.0 (from -r BiomedParse/assets/requirements/requirements.txt (line 28))\n",
            "  Downloading kornia-0.7.0-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting deepspeed==0.10.3 (from -r BiomedParse/assets/requirements/requirements.txt (line 29))\n",
            "  Downloading deepspeed-0.10.3.tar.gz (867 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.3/867.3 kB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting infinibatch==0.1.1 (from -r BiomedParse/assets/requirements/requirements.txt (line 31))\n",
            "  Downloading infinibatch-0.1.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting open-clip-torch==2.26.1 (from -r BiomedParse/assets/requirements/requirements.txt (line 32))\n",
            "  Downloading open_clip_torch-2.26.1-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.3.1->-r BiomedParse/assets/requirements/requirements.txt (line 6)) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.3.1->-r BiomedParse/assets/requirements/requirements.txt (line 6)) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.3.1->-r BiomedParse/assets/requirements/requirements.txt (line 6)) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas==2.0.3->-r BiomedParse/assets/requirements/requirements.txt (line 7)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas==2.0.3->-r BiomedParse/assets/requirements/requirements.txt (line 7)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.12/dist-packages (from pandas==2.0.3->-r BiomedParse/assets/requirements/requirements.txt (line 7)) (2025.2)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.12/dist-packages (from timm==0.4.12->-r BiomedParse/assets/requirements/requirements.txt (line 8)) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm==0.4.12->-r BiomedParse/assets/requirements/requirements.txt (line 8)) (0.23.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from fvcore==0.1.5.post20221221->-r BiomedParse/assets/requirements/requirements.txt (line 11)) (4.67.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.12/dist-packages (from fvcore==0.1.5.post20221221->-r BiomedParse/assets/requirements/requirements.txt (line 11)) (3.1.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from fvcore==0.1.5.post20221221->-r BiomedParse/assets/requirements/requirements.txt (line 11)) (0.9.0)\n",
            "Collecting iopath>=0.1.7 (from fvcore==0.1.5.post20221221->-r BiomedParse/assets/requirements/requirements.txt (line 11))\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.34.0->-r BiomedParse/assets/requirements/requirements.txt (line 12)) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from transformers==4.34.0->-r BiomedParse/assets/requirements/requirements.txt (line 12)) (0.35.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.34.0->-r BiomedParse/assets/requirements/requirements.txt (line 12)) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.34.0->-r BiomedParse/assets/requirements/requirements.txt (line 12)) (2.32.4)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers==4.34.0->-r BiomedParse/assets/requirements/requirements.txt (line 12))\n",
            "  Downloading tokenizers-0.14.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.34.0->-r BiomedParse/assets/requirements/requirements.txt (line 12)) (0.6.2)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.12/dist-packages (from ftfy==6.1.1->-r BiomedParse/assets/requirements/requirements.txt (line 14)) (0.2.13)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk==3.8.1->-r BiomedParse/assets/requirements/requirements.txt (line 16)) (8.2.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from vision-datasets==0.2.2->-r BiomedParse/assets/requirements/requirements.txt (line 18)) (8.5.0)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from pycocotools==2.0.7->-r BiomedParse/assets/requirements/requirements.txt (line 20)) (3.10.0)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.12/dist-packages (from scikit-image==0.21.0->-r BiomedParse/assets/requirements/requirements.txt (line 25)) (3.5)\n",
            "Requirement already satisfied: imageio>=2.27 in /usr/local/lib/python3.12/dist-packages (from scikit-image==0.21.0->-r BiomedParse/assets/requirements/requirements.txt (line 25)) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image==0.21.0->-r BiomedParse/assets/requirements/requirements.txt (line 25)) (2025.9.9)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from scikit-image==0.21.0->-r BiomedParse/assets/requirements/requirements.txt (line 25)) (1.9.0)\n",
            "Requirement already satisfied: lazy_loader>=0.2 in /usr/local/lib/python3.12/dist-packages (from scikit-image==0.21.0->-r BiomedParse/assets/requirements/requirements.txt (line 25)) (0.4)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (from mup==1.0.0->-r BiomedParse/assets/requirements/requirements.txt (line 26)) (0.13.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate==0.23.0->-r BiomedParse/assets/requirements/requirements.txt (line 27)) (5.9.5)\n",
            "Collecting hjson (from deepspeed==0.10.3->-r BiomedParse/assets/requirements/requirements.txt (line 29))\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting ninja (from deepspeed==0.10.3->-r BiomedParse/assets/requirements/requirements.txt (line 29))\n",
            "  Using cached ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from deepspeed==0.10.3->-r BiomedParse/assets/requirements/requirements.txt (line 29)) (9.0.0)\n",
            "Collecting pydantic<2.0.0 (from deepspeed==0.10.3->-r BiomedParse/assets/requirements/requirements.txt (line 29))\n",
            "  Downloading pydantic-1.10.24-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6->-r BiomedParse/assets/requirements/requirements.txt (line 33)) (3.1.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6->-r BiomedParse/assets/requirements/requirements.txt (line 33)) (2.19.0)\n",
            "Collecting iopath>=0.1.7 (from fvcore==0.1.5.post20221221->-r BiomedParse/assets/requirements/requirements.txt (line 11))\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl.metadata (370 bytes)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6->-r BiomedParse/assets/requirements/requirements.txt (line 33)) (1.0.0)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6->-r BiomedParse/assets/requirements/requirements.txt (line 33)) (3.0.4)\n",
            "Requirement already satisfied: omegaconf>=2.1 in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6->-r BiomedParse/assets/requirements/requirements.txt (line 33)) (2.3.0)\n",
            "Collecting hydra-core>=1.1 (from detectron2==0.6->-r BiomedParse/assets/requirements/requirements.txt (line 33))\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting black==21.4b2 (from detectron2==0.6->-r BiomedParse/assets/requirements/requirements.txt (line 33))\n",
            "  Downloading black-21.4b2-py3-none-any.whl.metadata (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting appdirs (from black==21.4b2->detectron2==0.6->-r BiomedParse/assets/requirements/requirements.txt (line 33))\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: toml>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from black==21.4b2->detectron2==0.6->-r BiomedParse/assets/requirements/requirements.txt (line 33)) (0.10.2)\n",
            "Collecting pathspec<1,>=0.8.1 (from black==21.4b2->detectron2==0.6->-r BiomedParse/assets/requirements/requirements.txt (line 33))\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting mypy-extensions>=0.4.3 (from black==21.4b2->detectron2==0.6->-r BiomedParse/assets/requirements/requirements.txt (line 33))\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.34.0->-r BiomedParse/assets/requirements/requirements.txt (line 12)) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.34.0->-r BiomedParse/assets/requirements/requirements.txt (line 12)) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.34.0->-r BiomedParse/assets/requirements/requirements.txt (line 12)) (1.1.10)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core>=1.1->detectron2==0.6->-r BiomedParse/assets/requirements/requirements.txt (line 33)) (4.9.3)\n",
            "Collecting portalocker (from iopath>=0.1.7->fvcore==0.1.5.post20221221->-r BiomedParse/assets/requirements/requirements.txt (line 11))\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0.7->-r BiomedParse/assets/requirements/requirements.txt (line 20)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0.7->-r BiomedParse/assets/requirements/requirements.txt (line 20)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0.7->-r BiomedParse/assets/requirements/requirements.txt (line 20)) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0.7->-r BiomedParse/assets/requirements/requirements.txt (line 20)) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0.7->-r BiomedParse/assets/requirements/requirements.txt (line 20)) (3.2.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas==2.0.3->-r BiomedParse/assets/requirements/requirements.txt (line 7)) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.34.0->-r BiomedParse/assets/requirements/requirements.txt (line 12)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.34.0->-r BiomedParse/assets/requirements/requirements.txt (line 12)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.34.0->-r BiomedParse/assets/requirements/requirements.txt (line 12)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.34.0->-r BiomedParse/assets/requirements/requirements.txt (line 12)) (2025.8.3)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers==4.34.0->-r BiomedParse/assets/requirements/requirements.txt (line 12))\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.12->-r BiomedParse/assets/requirements/requirements.txt (line 8)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.12->-r BiomedParse/assets/requirements/requirements.txt (line 8)) (1.13.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.12->-r BiomedParse/assets/requirements/requirements.txt (line 8)) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.12->-r BiomedParse/assets/requirements/requirements.txt (line 8)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.12->-r BiomedParse/assets/requirements/requirements.txt (line 8)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.12->-r BiomedParse/assets/requirements/requirements.txt (line 8)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.12->-r BiomedParse/assets/requirements/requirements.txt (line 8)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.12->-r BiomedParse/assets/requirements/requirements.txt (line 8)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.12->-r BiomedParse/assets/requirements/requirements.txt (line 8)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.12->-r BiomedParse/assets/requirements/requirements.txt (line 8)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.12->-r BiomedParse/assets/requirements/requirements.txt (line 8)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.12->-r BiomedParse/assets/requirements/requirements.txt (line 8)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.12->-r BiomedParse/assets/requirements/requirements.txt (line 8)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.12->-r BiomedParse/assets/requirements/requirements.txt (line 8)) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.12->-r BiomedParse/assets/requirements/requirements.txt (line 8)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.12->-r BiomedParse/assets/requirements/requirements.txt (line 8)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.12->-r BiomedParse/assets/requirements/requirements.txt (line 8)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.12->-r BiomedParse/assets/requirements/requirements.txt (line 8)) (3.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6->-r BiomedParse/assets/requirements/requirements.txt (line 33)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6->-r BiomedParse/assets/requirements/requirements.txt (line 33)) (1.75.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6->-r BiomedParse/assets/requirements/requirements.txt (line 33)) (3.9)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6->-r BiomedParse/assets/requirements/requirements.txt (line 33)) (5.29.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6->-r BiomedParse/assets/requirements/requirements.txt (line 33)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6->-r BiomedParse/assets/requirements/requirements.txt (line 33)) (3.1.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.4->timm==0.4.12->-r BiomedParse/assets/requirements/requirements.txt (line 8)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6->-r BiomedParse/assets/requirements/requirements.txt (line 33)) (3.0.2)\n",
            "Downloading opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyYAML-6.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (724 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m725.0/725.0 kB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json_tricks-3.17.3-py2.py3-none-any.whl (27 kB)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading scikit_learn-1.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m121.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading timm-0.4.12-py3-none-any.whl (376 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.0/377.0 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m114.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2023.10.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (789 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m789.1/789.1 kB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading vision_datasets-0.2.2-py3-none-any.whl (39 kB)\n",
            "Downloading Cython-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia-0.7.0-py2.py3-none-any.whl (705 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m705.7/705.7 kB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading infinibatch-0.1.1-py3-none-any.whl (32 kB)\n",
            "Downloading open_clip_torch-2.26.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading black-21.4b2-py3-none-any.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.0/131.0 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Downloading pydantic-1.10.24-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m104.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.14.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Building wheels for collected packages: pillow, pandas, fvcore, sentencepiece, mpi4py, pycocotools, diffdist, scikit-image, mup, deepspeed, detectron2\n",
            "  Building wheel for pillow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pillow: filename=Pillow-9.4.0-cp312-cp312-linux_x86_64.whl size=1198806 sha256=97620da1c1308ab33c4bb2ba9ce976d3993e9a9629c486f954475307cb3d1eb1\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/bd/fa/c7606e3b0644710a556108233c428d43249d98e562ccf055b9\n",
            "\n",
            "  Building wheel for pandas (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandas: filename=pandas-2.0.3-cp312-cp312-linux_x86_64.whl size=42828329 sha256=d20dcbddbbebbfd6359c309a4d270717ddb4bfcb24865b219d9d7c5294f70e5f\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/95/b7/15a2a9958c1fde0807c23b05bfed1a32ff9c7225c55d270d27\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61397 sha256=7ba6ef712d918df9c658b44cafdc0b48c4608ff38c89299e6b1d4492633f2a12\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/9f/a5/e4f5b27454ccd4596bd8b62432c7d6b1ca9fa22aef9d70a16a\n",
            "  Building wheel for sentencepiece (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentencepiece: filename=sentencepiece-0.1.99-cp312-cp312-linux_x86_64.whl size=1266901 sha256=35cff00a78c1c2d6fd48c8388255dc8dddf2a91f52eb44a9e8e79f58ad72455e\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/8c/e0/65e33b1f4b8462dfc537a0cac02e5c03e1207564c300e4bde5\n",
            "  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-3.1.5-cp312-cp312-linux_x86_64.whl size=3104675 sha256=59d9be841df4824e7d7c45417a8a384e5602b0ede21563997270505b34a3d4e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/d7/6f/b61734356eff503686f0f89388813130514384dd54bc5e51b2\n",
            "  Building wheel for pycocotools (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0.7-cp312-cp312-linux_x86_64.whl size=435631 sha256=65800147244b5470d3c9dc5e79cc292bcaf172abfacdfa4cdb254f5d12ce55dd\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/b8/6d/646852bb348f96f4928351fc4b023cdace78cb8f43d2244ded\n",
            "  Building wheel for diffdist (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffdist: filename=diffdist-0.1-py3-none-any.whl size=6535 sha256=0d92b36a1441751ae5193f1000c40c9b5ca07f6878aaeab4bd7a73f8db8f65bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/1a/54/85e77a3d1c1d47832ad78a6d98cb4e5111968f849d8706989b\n",
            "  Building wheel for scikit-image (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-image: filename=scikit_image-0.21.0-cp312-cp312-linux_x86_64.whl size=13942360 sha256=83fee72b495ec65c3b5fabb0c0ea6841128890a2ec1741b9a408406860769d26\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/2d/03/4a7ddd27b92cdf305bb4a12efdbed882a8af5a624cd01aeb92\n",
            "  Building wheel for mup (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mup: filename=mup-1.0.0-py3-none-any.whl size=23629 sha256=031ef06d2bcb38196c9c9d2a4e3b4d76d4f94e5d7880fba002db17daeccd532c\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/d2/b3/6c9337d770160e18d95735f139be998987fd43a23fb8126dfb\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.10.3-py3-none-any.whl size=907834 sha256=2d999aff9ccc55f1bdacbe1c378e82e13416fbab4a5cd19e43f86130ef29388f\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/46/3a/ac6e5b42eb02ceca2713a2d3a86f75ef3b7de83afd21176255\n",
            "  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for detectron2: filename=detectron2-0.6-cp312-cp312-linux_x86_64.whl size=6724272 sha256=271df853836dd1357681e727154fcc0ecd7baa65d2ab9385c19394f840beaa44\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-yszqnilw/wheels/50/6b/35/278a4c4da03b6c9f7f3f9cdf3c3aaeac620f2b8034c61af40f\n",
            "Successfully built pillow pandas fvcore sentencepiece mpi4py pycocotools diffdist scikit-image mup deepspeed detectron2\n",
            "Installing collected packages: sentencepiece, json_tricks, hjson, diffdist, appdirs, regex, pyyaml, pydantic, portalocker, pillow, pathspec, numpy, ninja, mypy-extensions, mpi4py, infinibatch, ftfy, einops, cython, yacs, vision-datasets, pandas, opencv-python, nltk, iopath, huggingface-hub, black, tokenizers, scikit-learn, scikit-image, hydra-core, fvcore, transformers, pycocotools, kornia, deepspeed, accelerate, timm, mup, detectron2, open-clip-torch\n",
            "  Attempting uninstall: sentencepiece\n",
            "    Found existing installation: sentencepiece 0.2.1\n",
            "    Uninstalling sentencepiece-0.2.1:\n",
            "      Successfully uninstalled sentencepiece-0.2.1\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2024.11.6\n",
            "    Uninstalling regex-2024.11.6:\n",
            "      Successfully uninstalled regex-2024.11.6\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.9\n",
            "    Uninstalling pydantic-2.11.9:\n",
            "      Successfully uninstalled pydantic-2.11.9\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.3.0\n",
            "    Uninstalling pillow-11.3.0:\n",
            "      Successfully uninstalled pillow-11.3.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: einops\n",
            "    Found existing installation: einops 0.8.1\n",
            "    Uninstalling einops-0.8.1:\n",
            "      Successfully uninstalled einops-0.8.1\n",
            "  Attempting uninstall: cython\n",
            "    Found existing installation: Cython 3.0.12\n",
            "    Uninstalling Cython-3.0.12:\n",
            "      Successfully uninstalled Cython-3.0.12\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.12.0.88\n",
            "    Uninstalling opencv-python-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-4.12.0.88\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.9.1\n",
            "    Uninstalling nltk-3.9.1:\n",
            "      Successfully uninstalled nltk-3.9.1\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.35.0\n",
            "    Uninstalling huggingface-hub-0.35.0:\n",
            "      Successfully uninstalled huggingface-hub-0.35.0\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.0\n",
            "    Uninstalling tokenizers-0.22.0:\n",
            "      Successfully uninstalled tokenizers-0.22.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.25.2\n",
            "    Uninstalling scikit-image-0.25.2:\n",
            "      Successfully uninstalled scikit-image-0.25.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.56.1\n",
            "    Uninstalling transformers-4.56.1:\n",
            "      Successfully uninstalled transformers-4.56.1\n",
            "  Attempting uninstall: pycocotools\n",
            "    Found existing installation: pycocotools 2.0.10\n",
            "    Uninstalling pycocotools-2.0.10:\n",
            "      Successfully uninstalled pycocotools-2.0.10\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.10.1\n",
            "    Uninstalling accelerate-1.10.1:\n",
            "      Successfully uninstalled accelerate-1.10.1\n",
            "  Attempting uninstall: timm\n",
            "    Found existing installation: timm 1.0.19\n",
            "    Uninstalling timm-1.0.19:\n",
            "      Successfully uninstalled timm-1.0.19\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.0.3 which is incompatible.\n",
            "mcp 1.14.1 requires pydantic<3.0.0,>=2.11.0, but you have pydantic 1.10.24 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires pydantic<3.0.0,>=2.0.0, but you have pydantic 1.10.24 which is incompatible.\n",
            "imbalanced-learn 0.14.0 requires scikit-learn<2,>=1.4.2, but you have scikit-learn 1.3.1 which is incompatible.\n",
            "google-genai 1.38.0 requires pydantic<3.0.0,>=2.0.0, but you have pydantic 1.10.24 which is incompatible.\n",
            "mizani 0.13.5 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "langchain 0.3.27 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 1.10.24 which is incompatible.\n",
            "albumentations 2.0.8 requires pydantic>=2.9.2, but you have pydantic 1.10.24 which is incompatible.\n",
            "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.3.1 which is incompatible.\n",
            "diffusers 0.35.1 requires huggingface-hub>=0.34.0, but you have huggingface-hub 0.17.3 which is incompatible.\n",
            "gradio-client 1.13.0 requires huggingface-hub>=0.19.3, but you have huggingface-hub 0.17.3 which is incompatible.\n",
            "langchain-core 0.3.76 requires pydantic>=2.7.4, but you have pydantic 1.10.24 which is incompatible.\n",
            "textblob 0.19.0 requires nltk>=3.9, but you have nltk 3.8.1 which is incompatible.\n",
            "xarray 2025.9.0 requires pandas>=2.2, but you have pandas 2.0.3 which is incompatible.\n",
            "google-adk 1.14.1 requires pydantic<3.0.0,>=2.0, but you have pydantic 1.10.24 which is incompatible.\n",
            "google-adk 1.14.1 requires PyYAML<7.0.0,>=6.0.2, but you have pyyaml 6.0.1 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\n",
            "peft 0.17.1 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.17.3 which is incompatible.\n",
            "gradio 5.46.0 requires huggingface-hub<1.0,>=0.33.5, but you have huggingface-hub 0.17.3 which is incompatible.\n",
            "gradio 5.46.0 requires pydantic<2.12,>=2.0, but you have pydantic 1.10.24 which is incompatible.\n",
            "datasets 4.0.0 requires huggingface-hub>=0.24.0, but you have huggingface-hub 0.17.3 which is incompatible.\n",
            "sentence-transformers 5.1.0 requires huggingface-hub>=0.20.0, but you have huggingface-hub 0.17.3 which is incompatible.\n",
            "sentence-transformers 5.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.34.0 which is incompatible.\n",
            "cuml-cu12 25.6.0 requires scikit-learn>=1.5, but you have scikit-learn 1.3.1 which is incompatible.\n",
            "pydantic-settings 2.10.1 requires pydantic>=2.7.0, but you have pydantic 1.10.24 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "arviz 0.22.0 requires pandas>=2.1.0, but you have pandas 2.0.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.23.0 appdirs-1.4.4 black-21.4b2 cython-3.0.2 deepspeed-0.10.3 detectron2-0.6 diffdist-0.1 einops-0.8.0 ftfy-6.1.1 fvcore-0.1.5.post20221221 hjson-3.1.0 huggingface-hub-0.17.3 hydra-core-1.3.2 infinibatch-0.1.1 iopath-0.1.9 json_tricks-3.17.3 kornia-0.7.0 mpi4py-3.1.5 mup-1.0.0 mypy-extensions-1.1.0 ninja-1.13.0 nltk-3.8.1 numpy-1.26.4 open-clip-torch-2.26.1 opencv-python-4.8.1.78 pandas-2.0.3 pathspec-0.12.1 pillow-9.4.0 portalocker-3.2.0 pycocotools-2.0.7 pydantic-1.10.24 pyyaml-6.0.1 regex-2023.10.3 scikit-image-0.21.0 scikit-learn-1.3.1 sentencepiece-0.1.99 timm-0.4.12 tokenizers-0.14.1 transformers-4.34.0 vision-datasets-0.2.2 yacs-0.1.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "dcbc0fd76adb442d95d48e84d0a07a6b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "0A8aCfHb4sd-",
        "outputId": "a1019e85-e3ed-4bb4-be9d-f7df06b88152",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Get the absolute path of the BiomedParse folder\n",
        "biomedparse_path = os.path.abspath('BiomedParse')\n",
        "\n",
        "# Add the folder to sys.path if it's not already there\n",
        "if biomedparse_path not in sys.path:\n",
        "    sys.path.append(biomedparse_path)"
      ],
      "metadata": {
        "id": "lJR7kGvw5VDc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "from modeling.BaseModel import BaseModel\n",
        "from modeling import build_model\n",
        "from utilities.distributed import init_distributed\n",
        "from utilities.arguments import load_opt_from_config_files\n",
        "from utilities.constants import BIOMED_CLASSES\n",
        "from inference_utils.inference import interactive_infer_image\n",
        "from inference_utils.output_processing import check_mask_stats\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "vq__WGCt4045",
        "outputId": "d4398091-d939-468b-b2d0-b76869a73cf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/BiomedParse/modeling/vision/encoder/ops/modules/ms_deform_attn.py:87: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  :param input_flatten               (N, \\sum_{l=0}^{L-1} H_l \\cdot W_l, C)\n",
            "/usr/local/lib/python3.12/dist-packages/kornia/feature/lightglue.py:30: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deformable Transformer Encoder is not available.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt = load_opt_from_config_files([\"BiomedParse/configs/biomedparse_inference.yaml\"])\n",
        "opt = init_distributed(opt)"
      ],
      "metadata": {
        "id": "DLcwzafK5X3r"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_pth = 'hf_hub:microsoft/BiomedParse'\n",
        "model = BaseModel(opt, build_model(opt)).from_pretrained(pretrained_pth).eval().cuda()"
      ],
      "metadata": {
        "id": "unUCR3-85fh_",
        "outputId": "6df3c53e-e65b-4892-a242-469faf5777de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98,
          "referenced_widgets": [
            "6255ea09d432414e9dde5363c2424565",
            "e5542e7a1d204ff7bb73e1b5fbb6cde1",
            "98635535136a4b149d45522f9cd20566",
            "c05cbac3786b4543a93bd6f48e6193f4",
            "b7769a55c5a1421fb23e00636f89e711",
            "6a4104b087974ac2b648211b01af9012",
            "b1debaf622eb48028fcbb776253dae77",
            "8f1f1e0aaf8245748bc7185a0f92ddd9",
            "c71b3cd372f3454d9e497d0e1fc742c3",
            "d8c1860963e34eb4a94d7e7184a707e7",
            "7fe3be1cd7a84faa84ab3b20571297ec",
            "e25ea06f67224bb7b1e4e84b42aa27b3",
            "124716ab822c4876bc47836f1293723e",
            "bdf8658132cf40c5bc345362f9013c2f",
            "e1cbc270e3294531bd1afafda46a658b",
            "c6d06cc265e248dab07c4f85ae9f4ab3",
            "563aed450c874d8fb36e0b9120c77f3c",
            "fb8c483607324ffb8b8506b2dcd554ac",
            "3f6d18713b4a4dc297f9fe375f397e8b",
            "941d9d5313cb415a9d2043946650921f",
            "93e0e273afc64b618f9fde00ecfe9383",
            "01498f544208488b8d2cb3cd8f9b37f3"
          ]
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading biomedparse_v1.pt:   0%|          | 0.00/1.80G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6255ea09d432414e9dde5363c2424565"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading config.yaml:   0%|          | 0.00/4.54k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e25ea06f67224bb7b1e4e84b42aa27b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:utilities.model:$UNUSED$ criterion.empty_weight, Ckpt Shape: torch.Size([17])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    model.model.sem_seg_head.predictor.lang_encoder.get_text_embeddings(BIOMED_CLASSES + [\"background\"], is_eval=True)"
      ],
      "metadata": {
        "id": "keAo5AHR85Y-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RGB image input of shape (H, W, 3). Currently only batch size 1 is supported.\n",
        "image = Image.open('BiomedParse/examples/Part_1_516_pathology_breast.png', formats=['png'])\n",
        "image = image.convert('RGB')\n",
        "# text prompts querying objects in the image. Multiple ones can be provided.\n",
        "prompts = ['neoplastic cells', 'inflammatory cells']\n",
        "\n",
        "# load ground truth mask\n",
        "gt_masks = []\n",
        "for prompt in prompts:\n",
        "    gt_mask = Image.open(f\"BiomedParse/examples/Part_1_516_pathology_breast_{prompt.replace(' ', '+')}.png\", formats=['png'])\n",
        "    gt_mask = 1*(np.array(gt_mask.convert('RGB'))[:,:,0] > 0)\n",
        "    gt_masks.append(gt_mask)\n",
        "\n",
        "pred_mask = interactive_infer_image(model, image, prompts)\n",
        "text_prompt = ['left lung', 'lung', 'right lung', 'viral pneumonia']\n",
        "# prediction with ground truth mask\n",
        "for i, pred in enumerate(pred_mask):\n",
        "    gt = gt_masks[i]\n",
        "    dice = (1*(pred>0.5) & gt).sum() * 2.0 / (1*(pred>0.5).sum() + gt.sum())\n",
        "    print(f'Dice score for {prompts[i]}: {dice:.4f}')\n",
        "    check_mask_stats(image, pred_mask[i]*255, 'X-Ray-Chest', text_prompt[i])\n",
        "    print(f'p-value for {prompts[i]}: {p_value:.4f}')"
      ],
      "metadata": {
        "id": "qTmb1Udq7cOs",
        "outputId": "12ac0e3b-f389-4910-9d5a-afea663b7683",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416,
          "referenced_widgets": [
            "d008705e8e9048568bb514f4e95b399c",
            "1b76e7917e0f4becaa9d19ad963de50b",
            "c35981261365430cac455ee44679d6c7",
            "a8a9fe02009743cabaf38685ba69c933",
            "d4367e9997ca4a69804b4dae91027033",
            "8f238ff9e2e2417c8ac2c8e2ee58ac73",
            "4eb484582a58456fb6cbe517930a30f9",
            "1eca9fcaffaa4994894925223875a7ac",
            "1032b24d86344c1a8057dfc1ccbfa4cc",
            "497ffc38f648466e8cfea5822cb0aa50",
            "bd04ea9abbb24ad1af3e3102eaf2da9a"
          ]
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dice score for neoplastic cells: 0.9022\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading target_dist.json:   0%|          | 0.00/11.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d008705e8e9048568bb514f4e95b399c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Currently support targets for X-Ray-Chest: ['left lung', 'lung', 'right lung', 'viral pneumonia']",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4063664021.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mdice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Dice score for {prompts[i]}: {dice:.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mcheck_mask_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'X-Ray-Chest'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'p-value for {prompts[i]}: {p_value:.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/BiomedParse/inference_utils/output_processing.py\u001b[0m in \u001b[0;36mcheck_mask_stats\u001b[0;34m(img, mask, modality_type, target)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodality_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Currently support targets for {modality_type}: {list(target_dist[modality_type].keys())}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Currently support targets for X-Ray-Chest: ['left lung', 'lung', 'right lung', 'viral pneumonia']"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login\n"
      ],
      "metadata": {
        "id": "inTbo7QX6tAO",
        "outputId": "ef2c1887-514b-4298-b4ae-996be2f7a5e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "    \n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) Y\n",
            "Token is valid (permission: read).\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/microsoft/BiomedParse/resolve/main/biomedparse_v1.pt"
      ],
      "metadata": {
        "id": "LHFFQ4Bx5h25",
        "outputId": "101b5c24-1d5b-4e89-a65b-2074f9984e8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-25 08:09:25--  https://huggingface.co/microsoft/BiomedParse/resolve/main/biomedparse_v1.pt\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.16, 18.239.50.103, 18.239.50.80, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 401 Unauthorized\n",
            "\n",
            "Username/Password Authentication Failed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-12T09:39:54.418700Z",
          "start_time": "2020-09-12T09:39:54.415303Z"
        },
        "id": "16gWjoEUXOhl"
      },
      "source": [
        "## Dependencies and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jc7ZqfooYZnD"
      },
      "outputs": [],
      "source": [
        "#@title Install dependencies\n",
        "\n",
        "!pip install -q omegaconf torchaudio pydub\n",
        "\n",
        "import os\n",
        "from os.path import exists\n",
        "\n",
        "if not exists('silero-models'):\n",
        "  !git clone -q --depth 1 https://github.com/snakers4/silero-models\n",
        "\n",
        "%cd silero-models\n",
        "\n",
        "# silero imports\n",
        "import torch\n",
        "import random\n",
        "from glob import glob\n",
        "from omegaconf import OmegaConf\n",
        "from src.silero.utils import (init_jit_model,\n",
        "                       split_into_batches,\n",
        "                       read_audio,\n",
        "                       read_batch,\n",
        "                       prepare_model_input)\n",
        "from colab_utils import (record_audio,\n",
        "                         audio_bytes_to_np,\n",
        "                         upload_audio)\n",
        "\n",
        "device = torch.device('cpu')   # you can use any pytorch device\n",
        "models = OmegaConf.load('models.yml')\n",
        "\n",
        "# imports for uploading/recording\n",
        "import numpy as np\n",
        "import ipywidgets as widgets\n",
        "from scipy.io import wavfile\n",
        "from IPython.display import Audio, display, clear_output\n",
        "from torchaudio.functional import vad\n",
        "\n",
        "\n",
        "# wav to text method\n",
        "def wav_to_text(f='test.wav'):\n",
        "  batch = read_batch([f])\n",
        "  input = prepare_model_input(batch, device=device)\n",
        "  output = model(input)\n",
        "  return decoder(output[0].cpu())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6QIeg7XffsO"
      },
      "source": [
        "## Transcribe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NJAOV1bbhEv0"
      },
      "outputs": [],
      "source": [
        "#@markdown { run: \"auto\" }\n",
        "\n",
        "language = \"English\" #@param [\"English\", \"German\", \"Spanish\"]\n",
        "\n",
        "print(language)\n",
        "if language == 'German':\n",
        "  model, decoder = init_jit_model(models.stt_models.de.latest.jit, device=device)\n",
        "elif language == \"Spanish\":\n",
        "  model, decoder = init_jit_model(models.stt_models.es.latest.jit, device=device)\n",
        "else:\n",
        "  model, decoder = init_jit_model(models.stt_models.en.latest.jit, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FYsz_90gTQh-"
      },
      "outputs": [],
      "source": [
        "#@markdown { run: \"auto\" }\n",
        "\n",
        "use_VAD = \"No\" #@param [\"Yes\", \"No\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QttWasy5hUd6"
      },
      "outputs": [],
      "source": [
        "#@markdown Either record audio from microphone or upload audio from file (.mp3 or .wav) { run: \"auto\" }\n",
        "\n",
        "record_or_upload = \"Record\" #@param [\"Record\", \"Upload (.mp3 or .wav)\"]\n",
        "record_seconds =   4#@param {type:\"number\", min:1, max:10, step:1}\n",
        "sample_rate = 16000\n",
        "\n",
        "def _apply_vad(audio, boot_time=0, trigger_level=9, **kwargs):\n",
        "  print('\\nVAD applied\\n')\n",
        "  vad_kwargs = dict(locals().copy(), **kwargs)\n",
        "  vad_kwargs['sample_rate'] = sample_rate\n",
        "  del vad_kwargs['kwargs'], vad_kwargs['audio']\n",
        "  audio = vad(torch.flip(audio, ([0])), **vad_kwargs)\n",
        "  return vad(torch.flip(audio, ([0])), **vad_kwargs)\n",
        "\n",
        "def _recognize(audio):\n",
        "  display(Audio(audio, rate=sample_rate, autoplay=True))\n",
        "  if use_VAD == \"Yes\":\n",
        "    audio = _apply_vad(audio)\n",
        "  wavfile.write('test.wav', sample_rate, (32767*audio).numpy().astype(np.int16))\n",
        "  transcription = wav_to_text()\n",
        "  print('\\n\\nTRANSCRIPTION:\\n')\n",
        "  print(transcription)\n",
        "\n",
        "def _record_audio(b):\n",
        "  clear_output()\n",
        "  audio = record_audio(record_seconds)\n",
        "  wavfile.write('recorded.wav', sample_rate, (32767*audio).numpy().astype(np.int16))\n",
        "  _recognize(audio)\n",
        "\n",
        "def _upload_audio(b):\n",
        "  clear_output()\n",
        "  audio = upload_audio()\n",
        "  _recognize(audio)\n",
        "  return audio\n",
        "\n",
        "if record_or_upload == \"Record\":\n",
        "  button = widgets.Button(description=\"Record Speech\")\n",
        "  button.on_click(_record_audio)\n",
        "  display(button)\n",
        "else:\n",
        "  audio = _upload_audio(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "E-bFGpn_TQiW"
      },
      "outputs": [],
      "source": [
        "#@markdown Check audio after applying VAD { run: \"auto\" }\n",
        "\n",
        "if record_or_upload == \"Record\":\n",
        "  audio = read_audio('recorded.wav', sample_rate)\n",
        "display(Audio(_apply_vad(audio), rate=sample_rate, autoplay=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-11T13:31:58.954518Z",
          "start_time": "2020-09-11T13:31:58.952259Z"
        },
        "id": "nMkcU8sDXOh8"
      },
      "source": [
        "# PyTorch Example\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xj7emOprcPQ6"
      },
      "outputs": [],
      "source": [
        "#@title Install Dependencies\n",
        "\n",
        "# this assumes that you have a relevant version of PyTorch installed\n",
        "!pip install -q torchaudio omegaconf\n",
        "\n",
        "import os\n",
        "from os.path import exists\n",
        "\n",
        "if not exists('silero-models'):\n",
        "  !git clone -q --depth 1 https://github.com/snakers4/silero-models\n",
        "\n",
        "%cd silero-models\n",
        "\n",
        "import torch\n",
        "import random\n",
        "from glob import glob\n",
        "from omegaconf import OmegaConf\n",
        "from src.silero.utils import (init_jit_model,\n",
        "                       split_into_batches,\n",
        "                       read_batch,\n",
        "                       prepare_model_input)\n",
        "from IPython.display import display, Audio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYG1dBgBDN5S"
      },
      "source": [
        "## Minimal example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwKw-yMpDQTL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import zipfile\n",
        "import torchaudio\n",
        "from glob import glob\n",
        "\n",
        "device = torch.device('cpu')  # gpu also works, but our models are fast enough for CPU\n",
        "model, decoder, utils = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
        "                                       model='silero_stt',\n",
        "                                       jit_model='jit_xlarge',\n",
        "                                       language='en', # also available 'de', 'es'\n",
        "                                       device=device)\n",
        "(read_batch, split_into_batches,\n",
        " read_audio, prepare_model_input) = utils  # see function signature for details\n",
        "\n",
        "# download a single file, any format compatible with TorchAudio\n",
        "torch.hub.download_url_to_file('https://opus-codec.org/static/examples/samples/speech_orig.wav',\n",
        "                               dst ='speech_orig.wav', progress=True)\n",
        "test_files = glob('speech_orig.wav')\n",
        "batches = split_into_batches(test_files, batch_size=10)\n",
        "input = prepare_model_input(read_batch(batches[0]),\n",
        "                            device=device)\n",
        "\n",
        "output = model(input)\n",
        "for example in output:\n",
        "    print(decoder(example.cpu()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8r3DW7IgkJil"
      },
      "source": [
        "## More examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-11T14:21:25.234818Z",
          "start_time": "2020-09-11T14:21:25.218179Z"
        },
        "id": "GE0S5kmdXOiG"
      },
      "outputs": [],
      "source": [
        "models = OmegaConf.load('models.yml')  # all available models are listed in the yml file\n",
        "print(list(models.stt_models.keys()),\n",
        "      list(models.stt_models.en.keys()),\n",
        "      list(models.stt_models.en.latest.keys()),\n",
        "      models.stt_models.en.latest.jit)\n",
        "device = torch.device('cpu')   # you can use any pytorch device\n",
        "model, decoder = init_jit_model(models.stt_models.en.latest.jit, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-11T14:21:26.056045Z",
          "start_time": "2020-09-11T14:21:26.040771Z"
        },
        "id": "GSUsZ7cqXOiL"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cpu')   # you can use any pytorch device\n",
        "model, decoder = init_jit_model(models.stt_models.en.latest.jit, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-11T14:25:14.996913Z",
          "start_time": "2020-09-11T14:21:40.831866Z"
        },
        "id": "paW8mugZXOiP"
      },
      "outputs": [],
      "source": [
        "test_files = glob('*.wav')  # replace with your data\n",
        "batches = split_into_batches(test_files, batch_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-11T13:57:09.061692Z",
          "start_time": "2020-09-11T13:57:08.992493Z"
        },
        "id": "JryVNe5hXOiR"
      },
      "outputs": [],
      "source": [
        "# transcribe a set of files\n",
        "input = prepare_model_input(read_batch(random.sample(batches, k=1)[0]),\n",
        "                            device=device)\n",
        "output = model(input)\n",
        "for example in output:\n",
        "    print(decoder(example.cpu()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-11T14:38:32.972790Z",
          "start_time": "2020-09-11T14:38:31.605231Z"
        },
        "id": "FgvdCQRSXOiY"
      },
      "outputs": [],
      "source": [
        "# listen to one file\n",
        "batch = read_batch(random.sample(batches, k=1)[0])\n",
        "input = prepare_model_input(batch,\n",
        "                            device=device)\n",
        "output = model(input)\n",
        "\n",
        "for i, example in enumerate(output):\n",
        "    print(decoder(example.cpu()))\n",
        "    display(Audio(batch[i], rate=16000))  # audio was resampled to 16kHz\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zi4m9qp4X4ma"
      },
      "outputs": [],
      "source": [
        "# align example\n",
        "batch = read_batch(random.sample(batches, k=1)[0])\n",
        "input = prepare_model_input(batch,\n",
        "                            device=device)\n",
        "\n",
        "wav_len = input.shape[1] / 16000\n",
        "\n",
        "output = model(input)\n",
        "\n",
        "for i, example in enumerate(output):\n",
        "    print(decoder(example.cpu(), wav_len, word_align=True)[-1])\n",
        "    display(Audio(batch[i], rate=16000))  # audio was resampled to 16kHz\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfa1Za1JUgUw"
      },
      "source": [
        "# ONNX Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ku78lggJUm_3"
      },
      "outputs": [],
      "source": [
        "#@title Install and Import Dependencies\n",
        "\n",
        "# this assumes that you have a relevant version of PyTorch installed\n",
        "!pip install -q torchaudio omegaconf onnx onnxruntime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i72mHSBbaG3p"
      },
      "source": [
        "## Minimal example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ed20MdPEEt3C"
      },
      "outputs": [],
      "source": [
        "import onnx\n",
        "import torch\n",
        "import onnxruntime\n",
        "from omegaconf import OmegaConf\n",
        "\n",
        "language = 'en' # also available 'de', 'es'\n",
        "\n",
        "# load provided utils\n",
        "_, decoder, utils = torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_stt', language=language)\n",
        "(read_batch, split_into_batches,\n",
        " read_audio, prepare_model_input) = utils\n",
        "\n",
        " # see available models\n",
        "torch.hub.download_url_to_file('https://raw.githubusercontent.com/snakers4/silero-models/master/models.yml', 'models.yml')\n",
        "models = OmegaConf.load('models.yml')\n",
        "available_languages = list(models.stt_models.keys())\n",
        "assert language in available_languages\n",
        "\n",
        "# load the actual ONNX model\n",
        "torch.hub.download_url_to_file(models.stt_models.en.latest.onnx, 'model.onnx', progress=True)\n",
        "onnx_model = onnx.load('model.onnx')\n",
        "onnx.checker.check_model(onnx_model)\n",
        "ort_session = onnxruntime.InferenceSession('model.onnx')\n",
        "\n",
        "# download a single file, any format compatible with TorchAudio\n",
        "torch.hub.download_url_to_file('https://opus-codec.org/static/examples/samples/speech_orig.wav', dst ='speech_orig.wav', progress=True)\n",
        "test_files = ['speech_orig.wav']\n",
        "batches = split_into_batches(test_files, batch_size=10)\n",
        "input = prepare_model_input(read_batch(batches[0]))\n",
        "\n",
        "# actual onnx inference and decoding\n",
        "onnx_input = input.detach().cpu().numpy()\n",
        "ort_inputs = {'input': onnx_input}\n",
        "ort_outs = ort_session.run(None, ort_inputs)\n",
        "decoded = decoder(torch.Tensor(ort_outs[0])[0])\n",
        "print(decoded)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "colab_examples.ipynb",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6255ea09d432414e9dde5363c2424565": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5542e7a1d204ff7bb73e1b5fbb6cde1",
              "IPY_MODEL_98635535136a4b149d45522f9cd20566",
              "IPY_MODEL_c05cbac3786b4543a93bd6f48e6193f4"
            ],
            "layout": "IPY_MODEL_b7769a55c5a1421fb23e00636f89e711"
          }
        },
        "e5542e7a1d204ff7bb73e1b5fbb6cde1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a4104b087974ac2b648211b01af9012",
            "placeholder": "​",
            "style": "IPY_MODEL_b1debaf622eb48028fcbb776253dae77",
            "value": "Downloading biomedparse_v1.pt: 100%"
          }
        },
        "98635535136a4b149d45522f9cd20566": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f1f1e0aaf8245748bc7185a0f92ddd9",
            "max": 1803167371,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c71b3cd372f3454d9e497d0e1fc742c3",
            "value": 1803167371
          }
        },
        "c05cbac3786b4543a93bd6f48e6193f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8c1860963e34eb4a94d7e7184a707e7",
            "placeholder": "​",
            "style": "IPY_MODEL_7fe3be1cd7a84faa84ab3b20571297ec",
            "value": " 1.80G/1.80G [00:47&lt;00:00, 21.1MB/s]"
          }
        },
        "b7769a55c5a1421fb23e00636f89e711": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a4104b087974ac2b648211b01af9012": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1debaf622eb48028fcbb776253dae77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f1f1e0aaf8245748bc7185a0f92ddd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c71b3cd372f3454d9e497d0e1fc742c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d8c1860963e34eb4a94d7e7184a707e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fe3be1cd7a84faa84ab3b20571297ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e25ea06f67224bb7b1e4e84b42aa27b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_124716ab822c4876bc47836f1293723e",
              "IPY_MODEL_bdf8658132cf40c5bc345362f9013c2f",
              "IPY_MODEL_e1cbc270e3294531bd1afafda46a658b"
            ],
            "layout": "IPY_MODEL_c6d06cc265e248dab07c4f85ae9f4ab3"
          }
        },
        "124716ab822c4876bc47836f1293723e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_563aed450c874d8fb36e0b9120c77f3c",
            "placeholder": "​",
            "style": "IPY_MODEL_fb8c483607324ffb8b8506b2dcd554ac",
            "value": "Downloading config.yaml: 100%"
          }
        },
        "bdf8658132cf40c5bc345362f9013c2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f6d18713b4a4dc297f9fe375f397e8b",
            "max": 4537,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_941d9d5313cb415a9d2043946650921f",
            "value": 4537
          }
        },
        "e1cbc270e3294531bd1afafda46a658b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93e0e273afc64b618f9fde00ecfe9383",
            "placeholder": "​",
            "style": "IPY_MODEL_01498f544208488b8d2cb3cd8f9b37f3",
            "value": " 4.54k/4.54k [00:00&lt;00:00, 249kB/s]"
          }
        },
        "c6d06cc265e248dab07c4f85ae9f4ab3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "563aed450c874d8fb36e0b9120c77f3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb8c483607324ffb8b8506b2dcd554ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f6d18713b4a4dc297f9fe375f397e8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "941d9d5313cb415a9d2043946650921f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "93e0e273afc64b618f9fde00ecfe9383": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01498f544208488b8d2cb3cd8f9b37f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d008705e8e9048568bb514f4e95b399c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b76e7917e0f4becaa9d19ad963de50b",
              "IPY_MODEL_c35981261365430cac455ee44679d6c7",
              "IPY_MODEL_a8a9fe02009743cabaf38685ba69c933"
            ],
            "layout": "IPY_MODEL_d4367e9997ca4a69804b4dae91027033"
          }
        },
        "1b76e7917e0f4becaa9d19ad963de50b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f238ff9e2e2417c8ac2c8e2ee58ac73",
            "placeholder": "​",
            "style": "IPY_MODEL_4eb484582a58456fb6cbe517930a30f9",
            "value": "Downloading target_dist.json: 100%"
          }
        },
        "c35981261365430cac455ee44679d6c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1eca9fcaffaa4994894925223875a7ac",
            "max": 11739,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1032b24d86344c1a8057dfc1ccbfa4cc",
            "value": 11739
          }
        },
        "a8a9fe02009743cabaf38685ba69c933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_497ffc38f648466e8cfea5822cb0aa50",
            "placeholder": "​",
            "style": "IPY_MODEL_bd04ea9abbb24ad1af3e3102eaf2da9a",
            "value": " 11.7k/11.7k [00:00&lt;00:00, 1.18MB/s]"
          }
        },
        "d4367e9997ca4a69804b4dae91027033": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f238ff9e2e2417c8ac2c8e2ee58ac73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4eb484582a58456fb6cbe517930a30f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1eca9fcaffaa4994894925223875a7ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1032b24d86344c1a8057dfc1ccbfa4cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "497ffc38f648466e8cfea5822cb0aa50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd04ea9abbb24ad1af3e3102eaf2da9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}